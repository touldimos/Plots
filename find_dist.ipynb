{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import scipy.stats as st\n",
    "import seaborn as sns\n",
    "\n",
    "def find_dist(y, var):\n",
    "    x = np.arange(len(y))\n",
    "    size = len(y)\n",
    "\n",
    "    y_df = pd.DataFrame(y, columns=['Data'])\n",
    "    sc=StandardScaler() \n",
    "    yy = y.reshape (-1,1)\n",
    "    sc.fit(yy)\n",
    "    y_std =sc.transform(yy)\n",
    "    y_std = y_std.flatten()\n",
    "    y_std\n",
    "    del yy\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    dist_names = ['alpha','anglit','arcsine','beta','betaprime','bradford','burr','burr12','cauchy','chi','chi2','cosine','dgamma','dweibull','erlang','expon','exponnorm','exponweib','exponpow','f','fatiguelife','fisk','foldcauchy','foldnorm','genlogistic','genpareto','gennorm','genexpon','genextreme','gausshyper','gamma','gengamma','genhalflogistic','gilbrat','gompertz','gumbel_r','gumbel_l','halfcauchy','halflogistic','halfnorm','halfgennorm','hypsecant','invgamma','invgauss','invweibull','johnsonsb','johnsonsu','kstwobign','laplace','levy','levy_l','logistic','loggamma','loglaplace','lognorm','lomax','maxwell','mielke','nakagami','ncx2','ncf','nct','norm','pareto','pearson3','powerlaw','powerlognorm','powernorm','rdist','reciprocal','rayleigh','rice','recipinvgauss','semicircular','t','triang','truncexpon','truncnorm','tukeylambda','uniform','vonmises','vonmises_line','wald','weibull_min','weibull_max']\n",
    "    chi_square = []\n",
    "    p_values = []\n",
    "\n",
    "    percentile_bins = np.linspace(0,100,51)\n",
    "    percentile_cutoffs = np.percentile(y_std, percentile_bins)\n",
    "    observed_frequency, bins = (np.histogram(y_std, bins=percentile_cutoffs))\n",
    "    cum_observed_frequency = np.cumsum(observed_frequency)\n",
    "\n",
    "    for distribution in dist_names:\n",
    "        dist = getattr(scipy.stats, distribution)\n",
    "        param = dist.fit(y_std)\n",
    "\n",
    "        p = scipy.stats.kstest(y_std, distribution, args=param)[1]\n",
    "        p = np.around(p, 5)\n",
    "        p_values.append(p)    \n",
    "\n",
    "        cdf_fitted = dist.cdf(percentile_cutoffs, *param[:-2], loc=param[-2], \n",
    "                              scale=param[-1])\n",
    "        expected_frequency = []\n",
    "        for bin in range(len(percentile_bins)-1):\n",
    "            expected_cdf_area = cdf_fitted[bin+1] - cdf_fitted[bin]\n",
    "            expected_frequency.append(expected_cdf_area)\n",
    "\n",
    "        expected_frequency = np.array(expected_frequency) * size\n",
    "        cum_expected_frequency = np.cumsum(expected_frequency)\n",
    "        ss = sum (((cum_expected_frequency - cum_observed_frequency) ** 2) / cum_observed_frequency)\n",
    "        chi_square.append(ss)\n",
    "\n",
    "    results = pd.DataFrame()\n",
    "    results['Distribution'] = dist_names\n",
    "    results['chi_square'] = chi_square\n",
    "    results['p_value'] = p_values\n",
    "    results.sort_values(['chi_square'], inplace=True)\n",
    "    results = results[results['p_value'] >= 0.05]\n",
    "    print ('\\nDistributions sorted by goodness of fit:')\n",
    "    print ('----------------------------------------')\n",
    "    print (results.head(15))\n",
    "\n",
    "    number_of_bins = 100\n",
    "    bin_cutoffs = np.linspace(np.percentile(y,0), np.percentile(y,99),number_of_bins)\n",
    "\n",
    "    h = plt.hist(y, bins = bin_cutoffs, color='0.75')\n",
    "\n",
    "    number_distributions_to_plot = 3\n",
    "    dist_names = results['Distribution'].iloc[0:number_distributions_to_plot]\n",
    "    \n",
    "    parameters = []\n",
    "\n",
    "    for dist_name in dist_names:\n",
    "        dist = getattr(scipy.stats, dist_name)\n",
    "        param = dist.fit(y)\n",
    "        parameters.append(param)\n",
    "\n",
    "        pdf_fitted = dist.pdf(x, *param[:-2], loc=param[-2], scale=param[-1])\n",
    "        scale_pdf = np.trapz (h[0], h[1][:-1]) / np.trapz (pdf_fitted, x)\n",
    "        pdf_fitted *= scale_pdf\n",
    "\n",
    "        plt.plot(pdf_fitted, label=dist_name)\n",
    "\n",
    "        plt.xlim(np.percentile(y,1), np.percentile(y,99))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel('Freq')\n",
    "    plt.show()\n",
    "\n",
    "    dist_parameters = pd.DataFrame()\n",
    "    dist_parameters['Distribution'] = (\n",
    "            results['Distribution'].iloc[0:number_distributions_to_plot])\n",
    "    dist_parameters['Distribution parameters'] = parameters\n",
    "    \n",
    "    print ('\\nDistribution parameters:')\n",
    "    print ('------------------------')\n",
    "\n",
    "    for index, row in dist_parameters.iterrows():\n",
    "        print ('\\nDistribution:', row[0])\n",
    "        print ('Parameters:', row[1] )\n",
    "    return pdf_fitted\n",
    "\n",
    "# var = 'P6d'\n",
    "# find_dist(all_d[var].values, var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
